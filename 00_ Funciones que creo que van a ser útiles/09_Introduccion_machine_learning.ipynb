{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3201144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# importamos los modelos que necesitemos\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "from bootcampviztools import pinta_distribucion_categoricas, plot_categorical_numerical_relationship, plot_grouped_histograms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2739e2c6",
   "metadata": {},
   "source": [
    "# 1. Procesado tratamiento datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea62597",
   "metadata": {},
   "source": [
    "En nuestra checklist:\n",
    "\n",
    "* Objetivo de negocio:\n",
    "* Objetivo tecnico:\n",
    "* Tipo de modelado (supervisado, no supervisado): \n",
    "* Features:\n",
    "* Target, si hay (variable a predecir): \n",
    "* Tipo de problema (clasificación, regresión, etc): \n",
    "* Métrica de Evaluacion:\n",
    "* Separación Train-Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25810e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separación train-test\n",
    "train_set, test_set = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d485460",
   "metadata": {},
   "source": [
    "# 2. Proceso EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f7bdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertir variable numérica a categórica\n",
    "train_set[\"nombre_nueva_columna_categorica\"] = pd.cut(train_set[\"columna_numerica\"], bins=[0., 1.5, 3.0, 4.5, 6., np.inf], labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "# análisis univariante numéricas (histogramas solo de numéricas)\n",
    "train_set.hist(bins=50, figsize=(12, 8))\n",
    "plt.show()\n",
    "\n",
    "# análisis univariante categóricas\n",
    "pinta_distribucion_categoricas(train_set, [\"columas categoricas\"], relativa= True, mostrar_valores= True)\n",
    "\n",
    "# análisis multivariante categóricas vs target numerica\n",
    "plot_categorical_numerical_relationship(train_set, categorical_col= \"ocean_proximity\", numerical_col=\"target\")\n",
    "plot_categorical_numerical_relationship(train_set, categorical_col= \"income_cat\", numerical_col=\"target\")\n",
    "\n",
    "train_set.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", grid=True,\n",
    "             s=train_set[\"population\"] / 100, label=\"population\",\n",
    "             c=\"target\", cmap=\"jet\", colorbar=True,\n",
    "             legend=True, sharex=False, figsize=(10, 7))\n",
    "plt.show()\n",
    "\n",
    "# análisis multivariante numéricas vs target numerica\n",
    "corr_matrix = train_set.corr(numeric_only= True)\n",
    "corr_matrix[\"target\"].sort_values(ascending = False)\n",
    "columnas = corr_matrix[\"target\"][corr_matrix[\"target\"] > 0.07].index.to_list() # nos quedamos con las que tienen correlación alta\n",
    "sns.pairplot(train_set[columnas]);\n",
    "\n",
    "# analisis multivariante numericas vs target categorica\n",
    "sns.pairplot(\n",
    "    train_set[columnas_numericas],\n",
    "    hue=\"Clicked on Ad\", # variable target va a distinguir por colores\n",
    "    diag_kind=\"kde\",\n",
    "    plot_kws={\"alpha\": 0.6}\n",
    ")\n",
    "\n",
    "# creamos otras variables y volvemos a ver correlación\n",
    "\n",
    "# por último, hacemos nuestra lista de features con todo lo concluido.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a3be24",
   "metadata": {},
   "source": [
    "# 3. Tratamiento categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b06934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertir categórica a numérica ordinal \"ordinal encoding\"\n",
    "def ordinal_encoding(df, columna_categorica, lista_ordenada_valores):\n",
    "    '''\n",
    "    Docstring para ordinal_encoding\n",
    "    :param df: dataframe\n",
    "    :param columna_categorica: columa que quiero convertir de categórica a numérica\n",
    "    :param lista_ordenada_valores: lista ordenada de los valores de la categórica que quiero pasar a números\n",
    "    '''\n",
    "    ordinal_encoder = OrdinalEncoder(categories= [lista_ordenada_valores])\n",
    "    df[columna_categorica] = ordinal_encoder.fit_transform(df[[columna_categorica]])\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# convertir categórica a varias columnas de 1 y 0 (tantas columnas como valores tome) \"one hot encoding\"\n",
    "def one_hot_encoding(df, columna_categorica, tipo = int):\n",
    "    '''\n",
    "    Docstring para one_hot_encoding\n",
    "    \n",
    "    :param df: dataframe\n",
    "    :param columna_categorica: columna categorica que quiero convertir a dummie\n",
    "    :param tipo: int o bool\n",
    "    '''\n",
    "    df = pd.get_dummies(df, columns = [columna_categorica], dtype = tipo)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75cb5a6",
   "metadata": {},
   "source": [
    "# 4. Tratamiento numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4b58ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuando hay variables que toman valores muy pequeños y otras variables valores muy grandes, debemos escalarlas o normalizarlas para que unas\n",
    "# no afecten más que otras al modelo\n",
    "\n",
    "# primero ver las distribuciones:\n",
    "# si tiene heavy tail: transformacion log\n",
    "# si el rango de valores es muy grande pero está distribuida de forma homogenea min max scalin\n",
    "# si parece una distribución normal la normalizo a N(0, 1)\n",
    "\n",
    "# min-max scaling \"normalización entre 0 y 1 o -1 y 1 (mejor para redes neuronales)\" \n",
    "# cuando los rangos de valores son muy grandes o hay outliers...\n",
    "def min_max_escaling(df, lista_columas_numericas, rango=(0, 1)):\n",
    "    min_max_scaler = MinMaxScaler(feature_range=rango)\n",
    "    df[lista_columas_numericas] = min_max_scaler.fit_transform(df[lista_columas_numericas]), columns= lista_columas_numericas\n",
    "    return df\n",
    "\n",
    "# estandarización (lo convierte a normales de media 0 y desviación 1)\n",
    "def estandarizacion(df, lista_columas_numericas):\n",
    "    std_scaler = StandardScaler()\n",
    "    df[lista_columas_numericas] = std_scaler.fit_transform(df[lista_columas_numericas])\n",
    "    return df\n",
    "\n",
    "# transformado de distribuciones con log (cuando una variable tiene heavy tail una cola muy larga y los valores concentrados en un lado)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 3), sharey=True)\n",
    "train_set[\"total_rooms\"].hist(ax=axs[0], bins=50)\n",
    "train_set[\"total_rooms\"].apply(np.log).hist(ax=axs[1], bins=50)\n",
    "axs[0].set_xlabel(\"total rooms\")\n",
    "axs[1].set_xlabel(\"Log of total rooms\")\n",
    "axs[0].set_ylabel(\"Number of districts\")\n",
    "plt.show()\n",
    "\n",
    "def transformacion_log_numericas(df, lista_columas_numericas_heavy_tail):\n",
    "    min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    for col in lista_columas_numericas_heavy_tail: \n",
    "        df[f\"log_{col}\"] = df[col].apply(np.log)\n",
    "        df[col] = min_max_scaler.fit_transform(df[[f\"log_{col}\"]])\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b1df20",
   "metadata": {},
   "source": [
    "# 5. Proceso modelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15221e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejecutamos modelos\n",
    "lin_reg = LinearRegression()\n",
    "tree_reg = DecisionTreeRegressor(random_state = 42) # Necesita una inicialización aleatoria y la semilla permite que siempre sea la misma\n",
    "log_class = LogisticRegression()\n",
    "rforest_class = RandomForestClassifier(n_estimators= 20, max_depth= 3, max_leaf_nodes= 5)\n",
    "\n",
    "# primero separamos la variable target del dataset de train y además solo nos quedamos con las features:\n",
    "def modelado_y_prediccion_y_mse_del_train(train_df, features, target, modelo):\n",
    "    '''\n",
    "    modelo puede ser LinearRegression(), DecisionTreeRegressor(random_state = 42)...\n",
    "    '''\n",
    "    X = train_df[features].copy()\n",
    "    y= train_df[target]\n",
    "    modelo.fit(X, y)\n",
    "    train_pred = modelo.predict(X)\n",
    "    return X, y, modelo, train_pred\n",
    "\n",
    "# tomando lo que suelta la función anterior\n",
    "def mse_del_train(y, train_pred):\n",
    "    mse_train = mean_squared_error(y, train_pred)\n",
    "    print(f\"El error cuadrático medio de la predicción del target del train del modelo es {sqrt(mse_train)}\")\n",
    "    return mse_train\n",
    "\n",
    "\n",
    "# otra forma de ver el error es con la accuracy\n",
    "def accuracy(y, train_pred):\n",
    "    acc_train = accuracy_score(y, train_pred)\n",
    "    print(f\"El accuracy de la predicción del target del train del modelo es {acc_train}\")\n",
    "    return acc_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f03af9",
   "metadata": {},
   "source": [
    "# 6. Proceso evaluación y ajuste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41000a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comprobamos que no hay sobreajuste en el modelo \n",
    "# haciendo cross validation y viendo que el error mse del modelo y el error del cross validation sean parecidos (si son diferentes hay sobreajuste)\n",
    "def comparacion_errores_mse_cross_validation(X, y, train_pred, modelo, k = 10):\n",
    "    '''\n",
    "    X, y y train_pred lo devuelve la función anterior\n",
    "    modelo puede ser LinearRegression(), DecisionTreeRegressor(random_state = 42)...\n",
    "    k es el número de conjuntos en los que divido el train para hacer de nuevo el modelo por separado\n",
    "    '''\n",
    "\n",
    "    mse_train = mean_squared_error(y, train_pred)\n",
    "    rmses = -cross_val_score(modelo, X, y, scoring=\"neg_root_mean_squared_error\", cv=k) \n",
    "    print(f\"El error cuadrático medio del modelo es {sqrt(mse_train)}\")\n",
    "    print(f\"La media de los errores de los modelos al separar en {k} conjuntos de entrenamiento es {pd.Series(rmses).mean()}\")\n",
    "\n",
    "\n",
    "def comparacion_errores_accuracy_cross_validation(X, y, train_pred, modelo, k = 10):\n",
    "    '''\n",
    "    X, y y train_pred lo devuelve la función anterior\n",
    "    modelo puede ser LinearRegression(), DecisionTreeRegressor(random_state = 42)...\n",
    "    k es el número de conjuntos en los que divido el train para hacer de nuevo el modelo por separado\n",
    "    '''\n",
    "\n",
    "    acc_train = accuracy_score(y, train_pred)\n",
    "    rmses = cross_val_score(modelo, X, y, scoring=\"accuracy\", cv=k) \n",
    "    print(f\"La accuracy del modelo es {acc_train}\")\n",
    "    print(f\"La media de las accuracy de los modelos al separar en {k} conjuntos de entrenamiento es {pd.Series(rmses).mean()}\")\n",
    "\n",
    "\n",
    "\n",
    "# luego hacemos las mismas transformaciones al test que le hicimos al train\n",
    "\n",
    "# y por último, evaluamos con el modelo escogido sobre el test, y si el mse de mantiene cercano al mse del train, el modelo es bueno\n",
    "def prediccion_y_mse_del_test(test_df, features, target, modelo):\n",
    "    '''\n",
    "    modelo puede ser LinearRegression(), DecisionTreeRegressor(random_state = 42)...\n",
    "    '''\n",
    "\n",
    "    X_test = test_df[features].copy()\n",
    "    y_test = test_df[target]\n",
    "    test_pred = modelo.predict(X_test)\n",
    "    mse_test = mean_squared_error(y_test, test_pred)\n",
    "    return print(f\"El error cuadrático medio de la predicción del target del test del modelo es {sqrt(mse_test)}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
